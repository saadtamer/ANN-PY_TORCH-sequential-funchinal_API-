{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c9c936",
   "metadata": {},
   "source": [
    "# üè° California Housing Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bcf8e2",
   "metadata": {},
   "source": [
    "## üì¶ 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb8074",
   "metadata": {},
   "source": [
    "## üìÇ 2. Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(X.shape, y.shape)  # (20640, 8) (20640,)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cbfcb",
   "metadata": {},
   "source": [
    "## üî• 3. PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68164a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "x_train_t = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "x_test_t = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "model_torch = nn.Sequential(\n",
    "    nn.Linear(8, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.1),\n",
    "    nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.1),\n",
    "    nn.Linear(64, 32), nn.BatchNorm1d(32), nn.ReLU(), nn.Dropout(0.1),\n",
    "    nn.Linear(32, 16), nn.BatchNorm1d(16), nn.ReLU(), nn.Dropout(0.1),\n",
    "    nn.Linear(16, 8), nn.BatchNorm1d(8), nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_torch.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    model_torch.train()\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_torch(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    model_torch.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_torch(x_test_t)\n",
    "        val_loss = criterion(val_outputs, y_test_t).item()\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f505d9",
   "metadata": {},
   "source": [
    "## üìà 4. PyTorch Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_t = model_torch(x_test_t).numpy()\n",
    "    y_true_t = y_test_t.numpy()\n",
    "\n",
    "mse = mean_squared_error(y_true_t, y_pred_t)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true_t, y_pred_t)\n",
    "r2 = r2_score(y_true_t, y_pred_t)\n",
    "\n",
    "print(f\"Final Results (PyTorch): MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")\n",
    "\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\"); plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"PyTorch Training vs Validation Loss\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "plt.scatter(y_true_t, y_pred_t, alpha=0.5)\n",
    "plt.xlabel(\"True Values\"); plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"PyTorch: Predicted vs True\")\n",
    "plt.plot([y_true_t.min(), y_true_t.max()], [y_true_t.min(), y_true_t.max()], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f12c4",
   "metadata": {},
   "source": [
    "## üîµ 5. Keras Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = Sequential([\n",
    "    Dense(64, input_dim=8, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model_keras.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_keras.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
    "history = model_keras.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=300, batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e10f9",
   "metadata": {},
   "source": [
    "## üìä 6. Keras Sequential Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_k = model_keras.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred_k)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred_k)\n",
    "r2 = r2_score(y_test, y_pred_k)\n",
    "\n",
    "print(f\"Final Results (Keras Sequential): MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}\")\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\"); plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Keras Training vs Validation Loss\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "plt.scatter(y_test, y_pred_k, alpha=0.5)\n",
    "plt.xlabel(\"True Values\"); plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Keras Sequential: Predicted vs True\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774bc4e",
   "metadata": {},
   "source": [
    "## üü£ 7. Keras Functional API Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X.shape[1],))\n",
    "x = Dense(128)(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dense(4, activation='relu')(x)\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "model_func = Model(inputs, outputs)\n",
    "model_func.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_func.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
    "history_func = model_func.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=300, batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52aa64d",
   "metadata": {},
   "source": [
    "## üèÅ 8. Conclusion\n",
    "- ‚úÖ Compared PyTorch, Keras Sequential, and Keras Functional API models.  \n",
    "- üìå Reported metrics: **MSE, RMSE, MAE, R¬≤**.  \n",
    "- üöÄ Future improvements: hyperparameter tuning, deeper networks, experimenting with dropout rates."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}